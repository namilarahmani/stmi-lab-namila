{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5f3288",
   "metadata": {},
   "source": [
    "# Tuned XGBoost Modeling\n",
    "Works similarly to untuned model in xgboost_notuning.ipynb with addition of hyperparameter tuning through GridSearch. This code runs on each participant for multiple prediction variables and exports results - start and end columns for inputs and prediction column can be specified through \"start\", \"end\", and \"topredict\" variables. \n",
    "\n",
    "Only those variables, realdata, and csv name need to be modified when running different tests :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c9ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import warnings\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e70f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "realdata = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Documents\\\\stmi-lab-namila\\\\allmetrics1\")\n",
    "savedval = 0.111\n",
    "\n",
    "#run tuned model\n",
    "def basemodel(participant, arr, start, end, topredict, removesnacks, nodinners):\n",
    "    global realdata\n",
    "    global savedval\n",
    "    \n",
    "    test = realdata\n",
    "    \n",
    "    #remove specified entries\n",
    "    if nodinners:\n",
    "        test = test[test['Meal Type'] != \"dinner\"]\n",
    "    \n",
    "    if removesnacks:\n",
    "        if(len(test[test['snack in 3hrs'] == True]) == 0):\n",
    "            #if no snack meals are removed, don't rerun\n",
    "            arr.append(savedval)\n",
    "            return savedval\n",
    "        else:\n",
    "            test = test[test['snack in 3hrs'] == False]\n",
    "\n",
    "    valid = test[test['dexcom 3hr auc'] != \"error\"]\n",
    "    valid = valid[valid['mets 3 hr auc'] != \"error\"]\n",
    "    \n",
    "    X = valid.loc[:, start:end].to_numpy()    \n",
    "    Y = valid[topredict].to_numpy().astype(float)\n",
    "    warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)\n",
    "\n",
    "    #split into train and test sets\n",
    "    seed = 7\n",
    "    test_size = 0.25\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "    \n",
    "    # HYPERPARAM TUNING: define parameter grid and regressor\n",
    "    param_grid = {'alpha': [0.0, 0.5, 1.0, 2.0],\n",
    "                  'learning_rate': [0.3, 0.1, 0.01, 0.001],  # Learning rate of the model\n",
    "                  'max_depth': [2, 3, 4, 5, 6],  # Maximum depth of each tree\n",
    "                  'n_estimators': [100, 200, 250],  # Number of trees in the ensemble\n",
    "                  }\n",
    "    model = XGBRegressor()\n",
    "    #set up grid search cross-validation\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    #make model with best params\n",
    "    model = XGBRegressor(alpha = grid_search.best_params_['alpha'],\n",
    "                        learning_rate = grid_search.best_params_['learning_rate'],\n",
    "                        max_depth = grid_search.best_params_['max_depth'],\n",
    "                        n_estimators = grid_search.best_params_['n_estimators'])\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "\n",
    "#     # SHAP EXPLAINER\n",
    "#     explainer = shap.Explainer(model.predict, X_test)\n",
    "#     shap_values = explainer(X_train)\n",
    "#     shap.plots.bar(shap_values)\n",
    "    \n",
    "    #sicong's normalized rmse\n",
    "    np.seterr(divide='ignore')\n",
    "    errors = ((y_test - prediction)/y_test)**2\n",
    "    rmsre = (np.average(errors))**.5\n",
    "    arr.append(rmsre)\n",
    "    return rmsre\n",
    "\n",
    "#run all combos of meal removal\n",
    "def runfour(errors, start, end, topredict):\n",
    "    global savedval\n",
    "    savedval = basemodel(x, errors[0], start, end, topredict, 0, 1)\n",
    "    basemodel(x, errors[1], start, end, topredict, 1, 1)\n",
    "    savedval = basemodel(x, errors[2], start, end, topredict,  0, 0)\n",
    "    basemodel(x, errors[3], start, end, topredict, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533b1ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#participants = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26,27,28,29]\n",
    "participants = [1]\n",
    "inputerrors = [[],[],[],[]]\n",
    "inputerrors2 = [[],[],[],[]]\n",
    "predpeakh = [[],[],[],[]]\n",
    "predauc = [[],[],[],[]]\n",
    "prediauc = [[],[],[],[]]\n",
    "predpt = [[],[],[],[]]\n",
    "predpd = [[],[],[],[]]\n",
    "sbg = [[],[],[],[]]\n",
    "\n",
    "for x in participants:\n",
    "    print(x)\n",
    "    \n",
    "    global realdata\n",
    "    \n",
    "    # Specify where to read data from\n",
    "    #realdata = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Documents\\\\stmi-lab-namila\\\\allmetricsn{x}\")\n",
    "    realdata = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Documents\\\\stmi-lab-namila\\\\combined_dataset\")\n",
    "    \n",
    "    #predicting macros\n",
    "    start = 'peakheight'\n",
    "    end = 'mets 3 hr avg'\n",
    "    \n",
    "    runfour(inputerrors, start, end, 'carbs')\n",
    "    runfour(inputerrors2, start, end, 'calories')\n",
    "        \n",
    "    #predicting ppgr\n",
    "    start = 'mets 3 hr auc'\n",
    "    end = 'fat'\n",
    "\n",
    "    runfour(predpeakh, start, end, 'peakheight')\n",
    "    runfour(predauc, start, end, 'dexcom 3hr auc')\n",
    "    runfour(prediauc, start, end, 'iauc')\n",
    "    runfour(predpt, start, end, 'peaktime')\n",
    "    runfour(predpd, start, end, 'peakduration_40')\n",
    "    runfour(sbg, start, end, 'startbg')\n",
    "\n",
    "#export results\n",
    "df = pd.DataFrame({'participants': participants, \n",
    "                  'carbs bl raw rmsre': inputerrors[0], 'carbs bl removed rmsre': inputerrors[1],\n",
    "                  'carbs bld raw rmsre': inputerrors[2], 'carbs bld removed rmsre': inputerrors[3],\n",
    "                  'calories bl raw rmsre': inputerrors2[0], 'calories bl removed rmsre': inputerrors2[1],\n",
    "                  'calories bld raw rmsre': inputerrors2[2], 'calories bld removed rmsre': inputerrors2[3],\n",
    "                  'ph bl raw rmsre': predpeakh[0], 'ph bl removed rmsre': predpeakh[1],\n",
    "                  'ph bld raw rmsre': predpeakh[2], 'ph bld removed rmsre': predpeakh[3],\n",
    "                  'auc bl raw rmsre': predauc[0], 'auc bl removed rmsre': predauc[1],\n",
    "                  'auc bld raw rmsre': predauc[2], 'auc bld removed rmsre': predauc[3],\n",
    "                  'iauc bl raw rmsre': prediauc[0], 'iauc bl removed rmsre': prediauc[1],\n",
    "                  'iauc bld raw rmsre': prediauc[2], 'iauc bld removed rmsre': prediauc[3],\n",
    "                  'pt bl raw rmsre': predpt[0], 'pt bl removed rmsre': predpt[1],\n",
    "                  'pt bld raw rmsre': predpt[2], 'pt bld removed rmsre': predpt[3],\n",
    "                  'pd40 bl raw rmsre': predpd[0], 'pd40 bl removed rmsre': predpd[1],\n",
    "                  'pd40 bld raw rmsre': predpd[2], 'pd40 bld removed rmsre': predpd[3],\n",
    "                  'sbg bl raw rmsre': sbg[0], 'sbg bl removed rmsre': sbg[1],\n",
    "                  'sbg bld raw rmsre': sbg[2], 'sbg bld removed rmsre': sbg[3]\n",
    "                  })\n",
    "df.to_csv(\"combinedacthr\")\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f2a1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
