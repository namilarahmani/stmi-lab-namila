{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688560b1",
   "metadata": {},
   "source": [
    "## Activity and PPGR\n",
    "Calculates ppgr auc, mets auc, average level, and activeMins metrics with a datetime of each meal for 2hr and 3hr timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "caa2f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "864efeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read datafile for METs\n",
    "x=1\n",
    "datafile = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_Fitbit.csv\")\n",
    "time = datafile['mins'].to_numpy()\n",
    "mets = datafile['METs'].to_numpy()\n",
    "hr = datafile['HeartRate'].to_numpy()\n",
    "datafile['Date_Time'] = pd.to_datetime(datafile['Date_Time'])\n",
    "\n",
    "time = time[~np.isnan(time)]\n",
    "mets = mets[~np.isnan(mets)]\n",
    "hr = hr[~np.isnan(hr)]\n",
    "\n",
    "#read cgm datafiles\n",
    "dexcomdata = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_CGM_Dexcom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca387fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def libreLinearInterpolation(cgm_df):\n",
    "    # Convert the 'Date_Time' column to datetime type\n",
    "    cgm_df['Date_Time'] = pd.to_datetime(cgm_df['Date_Time'])\n",
    "    # Set the 'Date_Time' column as the index\n",
    "    cgm_df.set_index('Date_Time', inplace=True)\n",
    "    # Drop or fill missing values\n",
    "    cgm_df.dropna(inplace=True)  # Drop rows with missing values\n",
    "    # Fix duplicate error\n",
    "    cgm_df = cgm_df.loc[~cgm_df.index.duplicated(), :]\n",
    "    # Resample the DataFrame to 1-minute intervals and perform linear interpolation\n",
    "    cgm_df_interpolated = cgm_df.resample('1T').interpolate(method='linear')\n",
    "    # Reset the index back to a column\n",
    "    cgm_df_interpolated.reset_index(inplace=True)\n",
    "    return cgm_df_interpolated\n",
    "\n",
    "def dexcomLinearInterpolation(raw_cgm_df):\n",
    "    # Convert the 'Date_Time' column to datetime type\n",
    "    raw_cgm_df['Date_Time'] = pd.to_datetime(raw_cgm_df['Date_Time'])\n",
    "    # Set the seconds component to 0\n",
    "    raw_cgm_df['Date_Time'] = raw_cgm_df['Date_Time'].apply(lambda dt: dt.replace(second=0))\n",
    "    # Set the 'Date_Time' column as the index\n",
    "    raw_cgm_df.set_index('Date_Time', inplace=True)\n",
    "    # Resample the DataFrame to 1-minute intervals and perform linear interpolation\n",
    "    interpolated_cgm_df = raw_cgm_df.resample('1T').interpolate(method='linear')\n",
    "    interpolated_cgm_df\n",
    "    # Reset the index back to a column\n",
    "    interpolated_cgm_df.reset_index(inplace=True)\n",
    "    return interpolated_cgm_df\n",
    "\n",
    "def readData(x):\n",
    "    #get globals\n",
    "    global datafile\n",
    "    global time\n",
    "    global mets\n",
    "    global hr\n",
    "    global libredata\n",
    "    global dexcomdata \n",
    "    \n",
    "    #read datafile for METs\n",
    "    datafile = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_Fitbit.csv\")\n",
    "    time = datafile['mins'].to_numpy()\n",
    "    mets = datafile['METs'].to_numpy()\n",
    "    hr = datafile['HeartRate'].to_numpy()\n",
    "    datafile['Date_Time'] = pd.to_datetime(datafile['Date_Time'])\n",
    "\n",
    "    time = time[~np.isnan(time)]\n",
    "    mets = mets[~np.isnan(mets)]\n",
    "    hr = hr[~np.isnan(hr)]\n",
    "\n",
    "    #read cgm datafiles\n",
    "    #libredata = libreLinearInterpolation(pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_CGM_Libre.csv\")) \n",
    "    dexcomdata = dexcomLinearInterpolation(pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_CGM_Dexcom.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5bf5e",
   "metadata": {},
   "source": [
    "### Calculate metrics for all the meal times from a spreadsheet\n",
    "can export to csv or print yay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a405cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hrmax = []\n",
    "hrauc = []\n",
    "hriauc = []\n",
    "hrstart = []\n",
    "z1mins = []\n",
    "z2mins = []\n",
    "z3mins = []\n",
    "z4mins = []\n",
    "\n",
    "def activityMetrics(timestring):\n",
    "    tuples = zip(time,mets,hr)\n",
    "    arr = np.asarray(list(tuples))\n",
    "\n",
    "    #find start time\n",
    "    #target_time = datetime.strptime(timestring, '%m/%d/%Y %H:%M')\n",
    "    target_time = datetime.strptime(timestring, '%Y-%m-%d %H:%M:%S')\n",
    "    theday = datafile[datafile['Date_Time'].dt.date == target_time.date()]\n",
    "    starttime = theday.iloc[0]['Date_Time']\n",
    "    minutes = int((target_time - starttime).total_seconds() / 60 + theday.iloc[0]['mins'])\n",
    "\n",
    "    timeframe = 180\n",
    "    #filter to time interval\n",
    "    filtered = arr[arr[:,0] <= minutes + timeframe]\n",
    "    filtered = filtered[filtered[:,0] >= minutes]\n",
    "    activity = filtered[:,1]\n",
    "\n",
    "    #calculations\n",
    "    try:\n",
    "        au = auc(filtered[:,0], filtered[:,2])\n",
    "        st = filtered[0,2]\n",
    "        area = auc(filtered[:,0], activity)\n",
    "        \n",
    "        auc3.append(area)\n",
    "        hrmax.append(np.max(filtered[:,2]))\n",
    "        hrauc.append(au)\n",
    "        hrstart.append(st)\n",
    "        hriauc.append(au - timeframe*st)\n",
    "        \n",
    "    except ValueError:\n",
    "        auc3.append(\"error\")\n",
    "        hrmax.append(\"error\")\n",
    "        hrauc.append(\"error\")\n",
    "        hrstart.append(\"error\")\n",
    "        hriauc.append(\"error\")\n",
    "    \n",
    "    #for zones, use participant number to find age and store that as a variable    \n",
    "    \n",
    "    avg3.append(np.average(activity)/10)\n",
    "    activeMin2.append(len(activity[activity > 20]))\n",
    "    activeMin3.append(len(activity[activity > 30]))\n",
    "    activeMin4.append(len(activity[activity > 30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68cdf4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "peakheight = []\n",
    "peaktime = []\n",
    "pd40 = []\n",
    "startbg = []\n",
    "iauc = []\n",
    "\n",
    "def iaucAll(timestring, threehr): \n",
    "    datafile1 = dexcomdata\n",
    "    \n",
    "    time = datafile1['mins'].to_numpy()\n",
    "    bg = datafile1['BG'].to_numpy()\n",
    "    time = time[~np.isnan(time)]\n",
    "    bg = bg[~np.isnan(bg)]\n",
    "    datafile1['Date_Time'] = pd.to_datetime(datafile1['Date_Time'])\n",
    "    \n",
    "    tuples = zip(time,bg)\n",
    "    arr = np.asarray(list(tuples))\n",
    "    \n",
    "    #target_time = datetime.strptime(timestring, '%m/%d/%Y %H:%M')\n",
    "    target_time = datetime.strptime(timestring, '%Y-%m-%d %H:%M:%S')\n",
    "    theday = datafile1[datafile1['Date_Time'].dt.date == target_time.date()]\n",
    "    \n",
    "    try:\n",
    "        if(len(theday) == 0):\n",
    "            raise ValueError(\"Data for this date is not available\")\n",
    "        starttime = theday.iloc[0]['Date_Time']\n",
    "        minutes = int((target_time - starttime).total_seconds() / 60 + theday.iloc[0]['mins'])\n",
    "    \n",
    "        #filter to time interval\n",
    "        filtered = arr[arr[:,0] >= minutes]\n",
    "        filtered = filtered[filtered[:,0] <= minutes + 180]\n",
    "        cgmdata = filtered[:,1]\n",
    "        \n",
    "        area = auc(filtered[:,0], cgmdata)\n",
    "        \n",
    "        #check that start and end pts are available (will look for a better way later)\n",
    "        checkstart = filtered[filtered[:,0] == minutes]\n",
    "        checkend = filtered[filtered[:,0] == minutes + 180]\n",
    "        \n",
    "        if len(checkstart) == 0 or len(checkend) == 0:\n",
    "             raise ValueError('Endpoint not available')\n",
    "                        \n",
    "        peak = np.max(cgmdata)\n",
    "        ptime = filtered[np.argmax(cgmdata), 0]\n",
    "        pd4 = len(cgmdata[cgmdata > peak*.6])\n",
    "        start = cgmdata[0]\n",
    "        iaucval = area - start*180\n",
    "       \n",
    "    except ValueError:\n",
    "        area = \"error\"\n",
    "        peak = \"error\"\n",
    "        pd4 = \"error\"\n",
    "        ptime = \"error\"\n",
    "        start = \"error\"\n",
    "        iaucval = \"error\"\n",
    "        \n",
    "    threehr.append(area)\n",
    "    peakheight.append(peak)\n",
    "    pd40.append(pd4)\n",
    "    peaktime.append(ptime)\n",
    "    startbg.append(start)\n",
    "    iauc.append(iaucval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20434d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-09-25 08:21:00\n",
      "\n",
      "2021-09-25 12:22:00\n",
      "\n",
      "2021-09-25 17:57:00\n",
      "\n",
      "2021-09-26 10:03:00\n",
      "\n",
      "2021-09-26 13:27:00\n",
      "\n",
      "2021-09-26 17:14:00\n",
      "\n",
      "2021-09-27 10:33:00\n",
      "\n",
      "2021-09-27 14:24:00\n",
      "\n",
      "2021-09-27 19:34:00\n",
      "\n",
      "2021-09-28 09:41:00\n",
      "\n",
      "2021-09-28 13:15:00\n",
      "\n",
      "2021-09-28 18:03:00\n",
      "\n",
      "2021-09-29 09:28:00\n",
      "\n",
      "2021-09-29 13:05:00\n",
      "\n",
      "2021-09-29 18:03:00\n",
      "\n",
      "2021-09-30 07:35:00\n",
      "\n",
      "2021-09-30 12:25:00\n",
      "\n",
      "2021-09-30 18:54:00\n",
      "\n",
      "2021-10-01 09:55:00\n",
      "\n",
      "2021-10-01 13:49:00\n",
      "\n",
      "2021-10-01 18:17:00\n",
      "\n",
      "2021-10-02 08:48:00\n",
      "\n",
      "2021-10-02 13:16:00\n",
      "\n",
      "2021-10-02 18:50:00\n",
      "\n",
      "2021-10-03 09:59:00\n",
      "\n",
      "2021-10-03 14:30:00\n",
      "\n",
      "2021-10-03 19:04:00\n",
      "\n",
      "2021-10-04 08:09:00\n",
      "\n",
      "2021-10-04 15:45:00\n",
      "\n",
      "2021-10-04 17:58:00\n",
      "\n",
      "2021-10-05 08:23:00\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#calculate one person\n",
    "dthree = []\n",
    "auc3 = []\n",
    "activeMin2 = []\n",
    "activeMin3 = []\n",
    "activeMin4 = []\n",
    "avg3 = []\n",
    "peakheight = []\n",
    "peaktime = []\n",
    "pd40 = []\n",
    "startbg = []\n",
    "iauc = []\n",
    "\n",
    "participant = 2\n",
    "mldata = pd.read_excel(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\{str(participant).zfill(3)}.xlsx\").dropna()\n",
    "mldata['Meal Time'] = mldata['Meal Time'].to_numpy()\n",
    "readData(participant)\n",
    "    \n",
    "for i in mldata['Meal Time']:\n",
    "    print('\\n' + str(i))\n",
    "    activityMetrics(str(i))\n",
    "    iaucAll(str(i), dthree)\n",
    "\n",
    "df = pd.DataFrame({'Meal Time': mldata['Meal Time'], 'snack in 3hrs': mldata['snack'], 'Meal Type': mldata['Meal Type'],\n",
    "                   #'dexcom 2hr auc': dtwo, 'mets 2 hr auc': auc2, '2 hr activeMin': activeMin2, 'mets 2 hr avg': avg2,\n",
    "                   'peakheight': peakheight, 'peaktime': peaktime, 'peakduration_40': pd40, 'startbg': startbg, 'iauc': iauc,\n",
    "                   'dexcom 3hr auc':dthree, 'mets 3 hr auc': auc3, 'hrmax': hrmax,'activeMin_2': activeMin2, 'activeMin_3': activeMin3, 'activeMin_4': activeMin4,\n",
    "                   'mets 3 hr avg': avg3, 'calories':mldata['Calories'], 'carbs':mldata['Carbs'], 'protein':mldata['Protein'],  'fat':mldata['Fat']})\n",
    "# df.to_csv(f'allmetrics{x}')\n",
    "df.to_csv(f'test{x}')\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe628cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "participant number 26:\n",
      "2022-08-06 08:08:00\n",
      "2022-08-06 12:14:00\n",
      "2022-08-06 16:48:00\n",
      "2022-08-07 09:06:00\n",
      "2022-08-07 12:28:00\n",
      "2022-08-08 12:42:00\n",
      "2022-08-08 18:00:00\n",
      "2022-08-09 09:44:00\n",
      "2022-08-09 13:25:00\n",
      "2022-08-09 16:16:00\n",
      "2022-08-10 08:58:00\n",
      "2022-08-10 12:19:00\n",
      "2022-08-10 16:09:00\n",
      "2022-08-11 09:06:00\n",
      "2022-08-11 12:43:00\n",
      "2022-08-11 17:10:00\n",
      "2022-08-12 09:00:00\n",
      "2022-08-12 23:06:00\n",
      "2022-08-13 10:01:00\n",
      "2022-08-13 13:40:00\n",
      "2022-08-13 16:18:00\n",
      "2022-08-14 10:00:00\n",
      "2022-08-14 14:00:00\n",
      "2022-08-15 10:19:00\n",
      "2022-08-15 12:51:00\n",
      "2022-08-16 11:49:00\n",
      "\n",
      "participant number 27:\n",
      "2022-08-09 08:27:12\n",
      "2022-08-09 13:30:42\n",
      "2022-08-09 20:15:00\n",
      "2022-08-10 08:45:44\n",
      "2022-08-10 12:45:39\n",
      "2022-08-10 18:38:00\n",
      "2022-08-11 08:30:25\n",
      "2022-08-11 13:34:21\n",
      "2022-08-11 21:04:00\n",
      "2022-08-12 09:20:22\n",
      "2022-08-12 15:30:08\n",
      "2022-08-12 19:45:00\n",
      "2022-08-13 09:33:15\n",
      "2022-08-13 14:00:02\n",
      "2022-08-14 10:10:22\n",
      "2022-08-14 13:40:08\n",
      "2022-08-14 20:00:00\n",
      "2022-08-15 10:15:21\n",
      "2022-08-15 14:00:01\n",
      "2022-08-15 20:00:00\n",
      "2022-08-16 08:15:02\n",
      "2022-08-16 13:11:49\n",
      "2022-08-16 19:02:00\n",
      "2022-08-17 09:20:07\n",
      "2022-08-17 12:45:20\n",
      "2022-08-17 18:38:00\n",
      "2022-08-18 10:11:40\n",
      "2022-08-18 13:40:59\n",
      "2022-08-18 18:45:00\n",
      "2022-08-19 08:35:01\n",
      "\n",
      "participant number 28:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\namil\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\namil\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-16 08:08:09\n",
      "2022-08-16 12:40:06\n",
      "2022-08-16 18:57:00\n",
      "2022-08-17 09:04:33\n",
      "2022-08-17 12:51:32\n",
      "2022-08-17 18:58:00\n",
      "2022-08-18 09:25:56\n",
      "2022-08-18 12:40:39\n",
      "2022-08-18 18:53:00\n",
      "2022-08-19 09:12:25\n",
      "2022-08-19 12:29:40\n",
      "2022-08-19 19:53:00\n",
      "2022-08-20 08:59:45\n",
      "2022-08-20 12:51:38\n",
      "2022-08-20 19:52:00\n",
      "2022-08-21 09:38:36\n",
      "2022-08-21 12:23:01\n",
      "2022-08-21 18:47:00\n",
      "2022-08-22 09:11:59\n",
      "2022-08-22 13:01:30\n",
      "2022-08-22 19:56:00\n",
      "2022-08-23 09:45:44\n",
      "2022-08-23 12:30:38\n",
      "2022-08-24 08:59:21\n",
      "2022-08-24 12:39:48\n",
      "2022-08-24 20:10:00\n",
      "2022-08-25 09:33:59\n",
      "2022-08-25 12:33:02\n",
      "2022-08-26 09:33:51\n",
      "\n",
      "participant number 29:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\namil\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "C:\\Users\\namil\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-28 08:20:12\n",
      "2022-09-28 12:06:24\n",
      "2022-09-28 17:22:00\n",
      "2022-09-29 05:44:15\n",
      "2022-09-29 11:56:25\n",
      "2022-09-29 17:04:00\n",
      "2022-09-30 06:18:10\n",
      "2022-09-30 11:38:32\n",
      "2022-09-30 16:20:00\n",
      "2022-10-01 06:22:04\n",
      "2022-10-01 11:53:24\n",
      "2022-10-01 17:19:00\n",
      "2022-10-02 06:30:27\n",
      "2022-10-02 11:55:54\n",
      "2022-10-02 17:37:00\n",
      "2022-10-03 05:40:46\n",
      "2022-10-03 11:40:54\n",
      "2022-10-03 17:35:00\n",
      "2022-10-04 05:57:35\n",
      "2022-10-04 11:41:40\n",
      "2022-10-04 17:36:00\n",
      "2022-10-05 06:19:24\n",
      "2022-10-05 11:39:51\n",
      "2022-10-05 16:00:00\n",
      "2022-10-06 05:51:14\n",
      "2022-10-06 11:39:04\n",
      "2022-10-06 16:34:00\n",
      "2022-10-07 05:37:05\n",
      "2022-10-07 11:39:10\n",
      "2022-10-07 18:13:00\n",
      "2022-10-08 06:31:55\n",
      "done :)\n"
     ]
    }
   ],
   "source": [
    "#generate dataset for all participants\n",
    "participants = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26,27,28,29]\n",
    "for x in participants:\n",
    "    dthree = []\n",
    "    auc3 = []\n",
    "    activeMin2 = []\n",
    "    activeMin3 = []\n",
    "    activeMin4 = []\n",
    "    avg3 = []\n",
    "    peakheight = []\n",
    "    peaktime = []\n",
    "    pd40 = []\n",
    "    startbg = []\n",
    "    iauc = []\n",
    "    hrmax = []\n",
    "    hrauc = []\n",
    "    hriauc = []\n",
    "    hrstart = []\n",
    "    z1mins = []\n",
    "    z2mins = []\n",
    "    z3mins = []\n",
    "    z4mins = []\n",
    "\n",
    "    print(\"\\n\" + f\"participant number {x}:\")\n",
    "    mldata = pd.read_excel(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\{str(x).zfill(3)}.xlsx\").dropna()\n",
    "    mldata['Meal Time'] = mldata['Meal Time'].to_numpy()\n",
    "    readData(x)\n",
    "\n",
    "    for i in mldata['Meal Time']:\n",
    "        print(str(i))\n",
    "        activityMetrics(str(i))\n",
    "        iaucAll(str(i), dthree)\n",
    "\n",
    "    df = pd.DataFrame({'Meal Time': mldata['Meal Time'], 'snack in 3hrs': mldata['snack'], 'Meal Type': mldata['Meal Type'],\n",
    "                   #'dexcom 2hr auc': dtwo, 'mets 2 hr auc': auc2, '2 hr activeMin': activeMin2, 'mets 2 hr avg': avg2,\n",
    "                   'peakheight': peakheight, 'peaktime': peaktime, 'peakduration_40': pd40, 'startbg': startbg, 'iauc': iauc,\n",
    "                   'dexcom 3hr auc':dthree, 'mets 3 hr auc': auc3, 'hrmax': hrmax,'hrauc': hriauc,'hrauc': hrstart, 'hrauc': hrstart,\n",
    "                   'activeMin_2': activeMin2, 'activeMin_3': activeMin3, 'activeMin_4': activeMin4,\n",
    "                   'mets 3 hr avg': avg3, 'calories':mldata['Calories'], 'carbs':mldata['Carbs'], 'protein':mldata['Protein'],  'fat':mldata['Fat']})\n",
    "    df.to_csv(f'allmetrics{x}')\n",
    "    \n",
    "print(\"done :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49ab9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
