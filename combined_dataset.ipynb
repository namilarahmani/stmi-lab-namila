{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688560b1",
   "metadata": {},
   "source": [
    "## Activity and PPGR\n",
    "Calculates ppgr auc, mets auc, average level, and activeMins metrics with a datetime of each meal for 2hr and 3hr timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa2f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d92db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read datafile for METs\n",
    "x=1\n",
    "datafile = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_Fitbit.csv\")\n",
    "time = datafile['mins'].to_numpy()\n",
    "mets = datafile['METs'].to_numpy()\n",
    "datafile['Date_Time'] = pd.to_datetime(datafile['Date_Time'])\n",
    "\n",
    "time = time[~np.isnan(time)]\n",
    "mets = mets[~np.isnan(mets)]\n",
    "\n",
    "#read cgm datafiles\n",
    "libredata = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_CGM_Libre.csv\")\n",
    "dexcomdata = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_CGM_Dexcom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca387fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def libreLinearInterpolation(cgm_df):\n",
    "    # Convert the 'Date_Time' column to datetime type\n",
    "    cgm_df['Date_Time'] = pd.to_datetime(cgm_df['Date_Time'])\n",
    "    # Set the 'Date_Time' column as the index\n",
    "    cgm_df.set_index('Date_Time', inplace=True)\n",
    "    # Drop or fill missing values\n",
    "    cgm_df.dropna(inplace=True)  # Drop rows with missing values\n",
    "    # Fix duplicate error\n",
    "    cgm_df = cgm_df.loc[~cgm_df.index.duplicated(), :]\n",
    "    # Resample the DataFrame to 1-minute intervals and perform linear interpolation\n",
    "    cgm_df_interpolated = cgm_df.resample('1T').interpolate(method='linear')\n",
    "    # Reset the index back to a column\n",
    "    cgm_df_interpolated.reset_index(inplace=True)\n",
    "    return cgm_df_interpolated\n",
    "\n",
    "def dexcomLinearInterpolation(raw_cgm_df):\n",
    "    # Convert the 'Date_Time' column to datetime type\n",
    "    raw_cgm_df['Date_Time'] = pd.to_datetime(raw_cgm_df['Date_Time'])\n",
    "    # Set the seconds component to 0\n",
    "    raw_cgm_df['Date_Time'] = raw_cgm_df['Date_Time'].apply(lambda dt: dt.replace(second=0))\n",
    "    # Set the 'Date_Time' column as the index\n",
    "    raw_cgm_df.set_index('Date_Time', inplace=True)\n",
    "    # Resample the DataFrame to 1-minute intervals and perform linear interpolation\n",
    "    interpolated_cgm_df = raw_cgm_df.resample('1T').interpolate(method='linear')\n",
    "    interpolated_cgm_df\n",
    "    # Reset the index back to a column\n",
    "    interpolated_cgm_df.reset_index(inplace=True)\n",
    "    return interpolated_cgm_df\n",
    "\n",
    "def readData(x):\n",
    "    #get globals\n",
    "    global datafile\n",
    "    global time\n",
    "    global mets\n",
    "    global libredata\n",
    "    global dexcomdata \n",
    "    \n",
    "    #read datafile for METs\n",
    "    datafile = pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_Fitbit.csv\")\n",
    "    time = datafile['mins'].to_numpy()\n",
    "    mets = datafile['METs'].to_numpy()\n",
    "    datafile['Date_Time'] = pd.to_datetime(datafile['Date_Time'])\n",
    "\n",
    "    time = time[~np.isnan(time)]\n",
    "    mets = mets[~np.isnan(mets)]\n",
    "\n",
    "    #read cgm datafiles\n",
    "    libredata = libreLinearInterpolation(pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_CGM_Libre.csv\")) \n",
    "    dexcomdata = dexcomLinearInterpolation(pd.read_csv(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\CaM01-{str(x).zfill(3)}_CGM_Dexcom.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5bf5e",
   "metadata": {},
   "source": [
    "### Calculate metrics for all the meal times from a spreadsheet\n",
    "can export to csv or print yay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a405cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activityMetrics(timestring):\n",
    "    tuples = zip(time,mets)\n",
    "    arr = np.asarray(list(tuples))\n",
    "\n",
    "    #find start time\n",
    "    #target_time = datetime.strptime(timestring, '%m/%d/%Y %H:%M')\n",
    "    target_time = datetime.strptime(timestring, '%Y-%m-%d %H:%M:%S')\n",
    "    theday = datafile[datafile['Date_Time'].dt.date == target_time.date()]\n",
    "    starttime = theday.iloc[0]['Date_Time']\n",
    "    minutes = int((target_time - starttime).total_seconds() / 60 + theday.iloc[0]['mins'])\n",
    "\n",
    "    timeframe = 180\n",
    "    #filter to time interval\n",
    "    filtered = arr[arr[:,0] <= minutes + timeframe]\n",
    "    filtered = filtered[filtered[:,0] >= minutes]\n",
    "#     plt.plot(filtered[:,0], filtered[:,1], label = \"mets for 2 hrs\")\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "    #calculate iauc for that time interval\n",
    "    activity = filtered[:,1]\n",
    "    area = auc(filtered[:,0], activity)\n",
    "    \n",
    "    auc3.append(area)\n",
    "    avg3.append(np.average(activity)/10)\n",
    "    activeMin3.append(len(activity[activity > 20]))\n",
    "#     print(\"three hours auc:\", area)\n",
    "#     print(\"three hours average:\", np.average(activity)/10)\n",
    "#     print(\"three hours activeMins:\", len(activity[activity > 20]))\n",
    "\n",
    "    filtered = filtered[filtered[:,0] <= minutes + 120]\n",
    "    activity = filtered[:,1]\n",
    "    area = auc(filtered[:,0], activity)\n",
    "#     print(\"two hours auc:\", area)\n",
    "#     print(\"two hours average:\", np.average(activity)/10)\n",
    "#     print(\"two hours activeMins:\", len(activity[activity > 20]))\n",
    "    auc2.append(area)\n",
    "    avg2.append(np.average(activity)/10)\n",
    "    activeMin2.append(len(activity[activity > 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "68cdf4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iaucAll(timestring, twohr, threehr, libre): \n",
    "    datafile1 = libredata if libre else dexcomdata\n",
    "    \n",
    "    time = datafile1['mins'].to_numpy()\n",
    "    bg = datafile1['BG'].to_numpy()\n",
    "    time = time[~np.isnan(time)]\n",
    "    bg = bg[~np.isnan(bg)]\n",
    "    datafile1['Date_Time'] = pd.to_datetime(datafile1['Date_Time'])\n",
    "    \n",
    "    tuples = zip(time,bg)\n",
    "    arr = np.asarray(list(tuples))\n",
    "    \n",
    "    #target_time = datetime.strptime(timestring, '%m/%d/%Y %H:%M')\n",
    "    target_time = datetime.strptime(timestring, '%Y-%m-%d %H:%M:%S')\n",
    "    theday = datafile1[datafile1['Date_Time'].dt.date == target_time.date()]\n",
    "    \n",
    "    if(len(theday) != 0):\n",
    "        starttime = theday.iloc[0]['Date_Time']\n",
    "        minutes = int((target_time - starttime).total_seconds() / 60 + theday.iloc[0]['mins'])\n",
    "    \n",
    "        #filter to time interval\n",
    "        filtered = arr[arr[:,0] >= minutes]\n",
    "        filtered = filtered[filtered[:,0] <= minutes + 180]\n",
    "\n",
    "        try:\n",
    "            area = auc(filtered[:,0], filtered[:,1])\n",
    "            #check that start and end pts are available (will look for a better way later)\n",
    "            checkstart = filtered[filtered[:,0] == minutes]\n",
    "            checkend = filtered[filtered[:,0] == minutes + 180]\n",
    "            if len(checkstart) == 0 or len(checkend) == 0:\n",
    "                 raise ValueError('Endpoint not available')\n",
    "\n",
    "        except ValueError:\n",
    "            area = \"error\"\n",
    "        threehr.append(area)\n",
    "\n",
    "        filtered = filtered[filtered[:,0] <= minutes + 120]\n",
    "        try:\n",
    "            area = auc(filtered[:,0], filtered[:,1])\n",
    "        except ValueError:\n",
    "            area = \"error\"\n",
    "        twohr.append(area)\n",
    "    else:\n",
    "        twohr.append(\"no data\")\n",
    "        threehr.append(\"no data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20434d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-09-26 10:03:00\n",
      "\n",
      "2021-09-26 13:27:00\n",
      "\n",
      "2021-09-26 17:14:00\n",
      "\n",
      "2021-09-27 10:33:00\n",
      "\n",
      "2021-09-27 14:24:00\n",
      "\n",
      "2021-09-27 19:34:00\n",
      "\n",
      "2021-09-28 09:41:00\n",
      "\n",
      "2021-09-28 13:15:00\n",
      "\n",
      "2021-09-28 18:03:00\n",
      "\n",
      "2021-09-29 09:28:00\n",
      "\n",
      "2021-09-29 13:05:00\n",
      "\n",
      "2021-09-29 18:03:00\n",
      "\n",
      "2021-09-30 07:35:00\n",
      "\n",
      "2021-09-30 12:25:00\n",
      "\n",
      "2021-09-30 18:54:00\n",
      "\n",
      "2021-10-01 09:55:00\n",
      "\n",
      "2021-10-01 13:49:00\n",
      "\n",
      "2021-10-01 18:17:00\n",
      "\n",
      "2021-10-02 08:48:00\n",
      "\n",
      "2021-10-02 13:16:00\n",
      "\n",
      "2021-10-02 18:50:00\n",
      "\n",
      "2021-10-03 09:59:00\n",
      "\n",
      "2021-10-03 14:30:00\n",
      "\n",
      "2021-10-03 19:04:00\n",
      "\n",
      "2021-10-04 08:09:00\n",
      "\n",
      "2021-10-04 15:45:00\n",
      "\n",
      "2021-10-04 17:58:00\n",
      "\n",
      "2021-10-05 08:23:00\n"
     ]
    }
   ],
   "source": [
    "# #calculate one person\n",
    "# twohr = []\n",
    "# threehr = []\n",
    "# dtwo = []\n",
    "# dthree = []\n",
    "# auc2 = []\n",
    "# auc3 = []\n",
    "# activeMin2 = []\n",
    "# activeMin3 = []\n",
    "# avg2 = []\n",
    "# avg3 = []\n",
    "\n",
    "# participant = 2\n",
    "# mldata = pd.read_excel(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\00{participant}.xlsx\").dropna()\n",
    "# mldata['Meal Time'] = mldata['Meal Time'].to_numpy()\n",
    "# readData(participant)\n",
    "    \n",
    "# for i in mldata['Meal Time']:\n",
    "#     print('\\n' + str(i))\n",
    "#     activityMetrics(str(i))\n",
    "#     iaucAll(str(i), twohr, threehr, 1)\n",
    "#     iaucAll(str(i), dtwo, dthree, 0)\n",
    "\n",
    "# df = pd.DataFrame({'time': mldata['Meal Time'], 'ppgr 2 hr': twohr, 'ppgr 3 hr': threehr, \n",
    "#                    'two hr auc': auc2, 'two hr activeMin': activeMin2, 'two hr avg': avg2, \n",
    "#                    'three hr auc': auc3, 'three hr activeMin': activeMin3, 'three hr avg': avg3,\n",
    "#                   'd2': dtwo, 'd3':dthree})\n",
    "# df.to_csv(f'allmetrics{participant}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe628cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "participant number 22:\n",
      "2022-06-01 08:37:00\n",
      "2022-06-01 12:27:00\n",
      "2022-06-02 08:59:00\n",
      "2022-06-02 13:37:00\n",
      "2022-06-02 17:50:47\n",
      "2022-06-03 09:03:00\n",
      "2022-06-03 12:34:00\n",
      "2022-06-03 19:13:56\n",
      "2022-06-04 09:01:00\n",
      "2022-06-04 12:37:00\n",
      "2022-06-04 19:37:24\n",
      "2022-06-05 08:48:00\n",
      "2022-06-05 12:35:00\n",
      "2022-06-05 20:01:51\n",
      "2022-06-06 09:05:00\n",
      "2022-06-06 12:45:00\n",
      "2022-06-06 19:05:08\n",
      "2022-06-07 09:03:00\n",
      "2022-06-07 12:29:00\n",
      "2022-06-07 19:23:32\n",
      "2022-06-08 09:01:00\n",
      "2022-06-08 13:08:00\n",
      "2022-06-08 19:15:48\n",
      "2022-06-09 09:07:00\n",
      "2022-06-09 12:21:00\n",
      "2022-06-09 19:00:11\n",
      "2022-06-10 09:00:00\n",
      "2022-06-10 12:20:00\n",
      "2022-06-11 09:08:00\n",
      "done :)\n"
     ]
    }
   ],
   "source": [
    "#generate dataset for all participants\n",
    "participants = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,26,27,28,29]\n",
    "for x in participants:\n",
    "    twohr = []\n",
    "    threehr = []\n",
    "    dtwo = []\n",
    "    dthree = []\n",
    "    auc2 = []\n",
    "    auc3 = []\n",
    "    activeMin2 = []\n",
    "    activeMin3 = []\n",
    "    avg2 = []\n",
    "    avg3 = []\n",
    "\n",
    "    print(\"\\n\" + f\"participant number {x}:\")\n",
    "    mldata = pd.read_excel(f\"C:\\\\Users\\\\namil\\\\Downloads\\\\{str(x).zfill(3)}.xlsx\").dropna()\n",
    "    mldata['Meal Time'] = mldata['Meal Time'].to_numpy()\n",
    "    readData(x)\n",
    "\n",
    "    for i in mldata['Meal Time']:\n",
    "        print(str(i))\n",
    "        activityMetrics(str(i))\n",
    "        iaucAll(str(i), twohr, threehr, 1)\n",
    "        iaucAll(str(i), dtwo, dthree, 0)\n",
    "\n",
    "    df = pd.DataFrame({'time': mldata['Meal Time'],'ppgr 2 hr': twohr, 'ppgr 3 hr': threehr, \n",
    "                       'two hr auc': auc2, 'two hr activeMin': activeMin2, 'two hr avg': avg2, \n",
    "                       'three hr auc': auc3, 'three hr activeMin': activeMin3, 'three hr avg': avg3,\n",
    "                      'd2': dtwo, 'd3':dthree})\n",
    "    df.to_csv(f'allmetrics{x}')\n",
    "print(\"done :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb843f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
